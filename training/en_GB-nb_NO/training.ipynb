{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b399d1eb-66f9-46cd-965d-c45fca2d39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import display, HTML\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e144d3-0504-4d6f-a3c1-0df0d76ecb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    \"\"\"\n",
    "    Output: Translated text of the source text\n",
    "    :param src_text: source string\n",
    "    \"\"\" \n",
    "    \n",
    "    #Load data (needs to be changed to loading from BQ or bucket)\n",
    "    df = pd.read_csv('../../data/en_GB-nb_NO/en_GB-nb_NO_batch_0.csv', engine='python')\n",
    "\n",
    "    df = df[['source', 'target']] # will be redundent when setup \n",
    "    df['source'] = df['source'].apply(lambda s: str(s))\n",
    "    df['target'] = df['target'].apply(lambda s: str(s))\n",
    "\n",
    "    # Transform to HuggingFace Dataset\n",
    "    data = Dataset.from_pandas(pd.DataFrame({'translation': df.to_dict('records')})) \n",
    "\n",
    "    # Split data into training sets\n",
    "    train_test_valid = data.train_test_split(shuffle=True, seed=7, test_size=0.0015)\n",
    "    test_valid = train_test_valid['test'].train_test_split(shuffle=True, seed=7, test_size=0.5)\n",
    "\n",
    "    # Convert to train/validate/test\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_test_valid['train'],\n",
    "        'validation': test_valid['test'],\n",
    "        'test': test_valid['train']})\n",
    "     \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989f5644-1dcb-4147-a0b7-31f4266e3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_processing(dataset, source_len=128, target_len=128,\n",
    "                            source=\"source\", target=\"target\"):\n",
    "    \"\"\"\n",
    "    Output: Generates tokenized data using the attributes of the base model\n",
    "    :param dataset: raw dataset to transform\n",
    "    :param source_len: maximum sentence length for source string\n",
    "    :param target_len: maximum sentence length for target string\n",
    "    :param source: source language\n",
    "    :param target: target language\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = [s[source] for s in dataset[\"translation\"]]\n",
    "    targets = [s[target] for s in dataset[\"translation\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=source_len, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=target_len, truncation=True)\n",
    "        \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4f5deb-b075-4464-ab6b-547bfdcdea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions): # n.b. can add more metrics later\n",
    "    \"\"\"\n",
    "    Output: evaluation metrics to track model performance in training\n",
    "    :param predictions: output of predictions to decode\n",
    "    \"\"\"\n",
    "    \n",
    "    metric = load_metric(\"sacrebleu\")\n",
    "    \n",
    "    def process_text(predictions, labels):\n",
    "        preds = [pred.strip() for pred in predictions]\n",
    "        labels = [[label.strip()] for label in labels]\n",
    "        return preds, labels\n",
    "    \n",
    "    preds, labels = predictions\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = process_text(decoded_preds, decoded_labels)\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    \n",
    "    result = {k: round(v, 6) for k, v in result.items()} #round results\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd5d117-6c02-48da-8a62-19d55ff7b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load models and data collator\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like Helsinki-NLP/opus-mt-en-no is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m             )\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         )\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     raise ValueError(\n\u001b[0;32m--> 546\u001b[0;31m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16016/138843550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load models and data collator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0;32m--> 424\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             )\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise EnvironmentError(\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;34mf\"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it in the cached \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m                 \u001b[0;34mf\"files and it looks like {pretrained_model_name_or_path} is not the path to a directory containing a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0;34mf\"{configuration_file} file.\\nCheckout your internet connection or see how to run the library in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like Helsinki-NLP/opus-mt-en-no is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "model_name=\"Helsinki-NLP/opus-mt-en-no\"\n",
    "\n",
    "dataset = process_data()\n",
    "\n",
    "print('load models and data collator')\n",
    "trained_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722a6fba-3f0a-41e6-8a79-a635cdc50c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a528b3fd4e84589b817e1c0bf6e4de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e28636b6b249b283f92eee4a9adeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2868bcd476494aa08f5075fb664f7b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenization_processing, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87817cc-2a72-4ed3-b8ec-913c2a762825",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = str(datetime.now())\n",
    "\n",
    "batch_size=16\n",
    "learning_rate=2e-5 \n",
    "weight_decay=0.01\n",
    "save_limit=10\n",
    "epochs=20\n",
    "\n",
    "# n.b. need to add early stopping with longer training times\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"../../models/checkpoints/IKEA_MT_en_GB-it_IT_{time}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay = weight_decay,\n",
    "    save_total_limit = save_limit,\n",
    "    num_train_epochs = epochs,\n",
    "    predict_with_generate=True    \n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    trained_model,\n",
    "    args,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620c567-83c4-41ac-a9b8-f0eb1ee58933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "/home/jupyter/.virtualenvs/ikea-mt/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 199112\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 248900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8890' max='248900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8890/248900 30:08 < 13:33:49, 4.92 it/s, Epoch 0.71/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8000\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8000/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8500\n",
      "Configuration saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8500/config.json\n",
      "Model weights saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [../../models/checkpoints/IKEA_MT_en_GB-it_IT_2022-12-23 14:07:24.526177/checkpoint-3500] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "print('train model')\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d123cc7-4470-4e6a-8f92-f52760d932ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('save model')\n",
    "trainer.save_model('../../models/en_GB-it_IT/IKEA_MT-en_it_IT_' + time)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ikea-mt",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "ikea-mt",
   "language": "python",
   "name": "ikea-mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
